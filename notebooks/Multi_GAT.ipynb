{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"tepfg55IEomu","executionInfo":{"status":"ok","timestamp":1754371085806,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LjwDGkbBExSC","executionInfo":{"status":"ok","timestamp":1754371087422,"user_tz":-330,"elapsed":12,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["computation = 'cloud'"]},{"cell_type":"markdown","metadata":{"id":"Ol-bJqjfyImJ"},"source":["### cloud Import"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qzjhXgnMylbH","executionInfo":{"status":"ok","timestamp":1754371092261,"user_tz":-330,"elapsed":21,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["  # !pip install pyglib\n","  # !pip install torch\n","  # !pip install scikit-learn\n","  # !pip install torch-sparse\n","  # !pip install torchvision\n","  # !pip install torch-scatter\n","  # !pip install torch-geometric\n","  # !pip install munch\n","  # !pip install wandb\n","  # !pip install lz4\n","  # !pip install zstandard\n","  # !pip install zstd\n","  # !pip install tabulate"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104474,"status":"ok","timestamp":1754371196739,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"},"user_tz":-330},"id":"I1DYXKvdyMqD","outputId":"04ccbb1e-4d7c-4ad1-e8c5-88b94008b8d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyglib\n","  Downloading pyglib-0.1.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting python-gflags (from pyglib)\n","  Downloading python-gflags-3.1.2.tar.gz (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting glog (from pyglib)\n","  Downloading glog-0.3.1-py2.py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from glog->pyglib) (1.17.0)\n","Downloading glog-0.3.1-py2.py3-none-any.whl (7.8 kB)\n","Building wheels for collected packages: pyglib, python-gflags\n","  Building wheel for pyglib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyglib: filename=pyglib-0.1-py2.py3-none-any.whl size=4532 sha256=722c662dde8a3aa22ac8e6d2e9e02d8beb9b71d90c60fc1635102ad79b09beca\n","  Stored in directory: /root/.cache/pip/wheels/0d/c4/e6/bdb4a219df3f70db47bf78b23a61d1d2c5edd2275403f71046\n","  Building wheel for python-gflags (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-gflags: filename=python_gflags-3.1.2-py3-none-any.whl size=57371 sha256=d3fc95f9d2eb99d9aeea1ddfcad702bb1d776460761d3bfa011aebb61a319389\n","  Stored in directory: /root/.cache/pip/wheels/08/32/87/be6254803d81af495c135b8b662d4a076e7a91dc7766f05a25\n","Successfully built pyglib python-gflags\n","Installing collected packages: python-gflags, glog, pyglib\n","Successfully installed glog-0.3.1 pyglib-0.1 python-gflags-3.1.2\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n","torch installed with version 2.6.0+cu124\n"]}],"source":["!pip install pyglib\n","!pip install torch\n","!pip install torchvision\n","import torch\n","print(f'torch installed with version { torch.__version__ }')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20830,"status":"ok","timestamp":1754371217571,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"},"user_tz":-330},"id":"fc60vAllzJLL","outputId":"79847325-7da5-4980-f7c4-042e1ef441e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://pytorch-geometric.com/whl/torch-2.6.0+cu124.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2+pt26cu124\n","Looking in links: https://pytorch-geometric.com/whl/torch-2.6.0+cu124.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.16.0)\n","Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.18+pt26cu124\n"]}],"source":["!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.6.0+cu124.html\n","!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.6.0+cu124.html"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7642,"status":"ok","timestamp":1754371225226,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"},"user_tz":-330},"id":"okaPtTMuzdxf","outputId":"81f5d682-8070-4984-957f-26794ccc379f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.14)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.7.14)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.14.1)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.6.1\n"]}],"source":["!pip install torch-geometric"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44178,"status":"ok","timestamp":1754371269406,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"},"user_tz":-330},"id":"qOYO8H9_ziNo","outputId":"6c78090c-46bc-4c28-fcb1-d6442e22fc1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Collecting munch\n","  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n","Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Installing collected packages: munch\n","Successfully installed munch-4.0.0\n","Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (25.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.2)\n","Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.7.14)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","Collecting lz4\n","  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lz4\n","Successfully installed lz4-4.4.4\n","Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (0.23.0)\n","Collecting zstd\n","  Downloading zstd-1.5.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (23 kB)\n","Downloading zstd-1.5.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: zstd\n","Successfully installed zstd-1.5.7.2\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n"]}],"source":["!pip install scikit-learn\n","!pip install munch\n","!pip install wandb\n","!pip install lz4\n","!pip install zstandard\n","!pip install zstd\n","!pip install tabulate"]},{"cell_type":"markdown","metadata":{"id":"TITr06Uyzukv"},"source":["### .."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":21141,"status":"ok","timestamp":1754371290549,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"},"user_tz":-330},"id":"5Pu7EEWeGhon","outputId":"a3c2d594-c005-4baa-e3e5-7eac3ac4b5bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Searching for file :  found\n","['small']\n"]}],"source":["if computation=='local' :\n","    data_path = '../data/AML'\n","    model_load_path = '../models/GNN'\n","    model_save_path = '../models/GNN'\n","else :\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  data_path = '/content/drive/MyDrive/uco_fraud_detector/data/AML'\n","  model_load_path = '/content/drive/MyDrive/uco_fraud_detector/models/GNN'\n","  model_save_path = '/content/drive/MyDrive/uco_fraud_detector/models/GNN'\n","\n","\n","print('Searching for file : ','found' if os.path.exists(data_path) else 'not found')\n","print(os.listdir(data_path))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"C__ni9-Agf4A","executionInfo":{"status":"ok","timestamp":1754371311561,"user_tz":-330,"elapsed":21009,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import itertools\n","import logging\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from torch_geometric.data import Data, HeteroData\n","from torch_geometric.typing import OptTensor\n","import torch.nn as nn\n","from torch_geometric.nn import GINEConv, BatchNorm, Linear, GATConv, PNAConv, RGCNConv\n","import torch.nn.functional as F\n","import tqdm\n","from torch_geometric.transforms import BaseTransform\n","from typing import Union\n","from torch_geometric.loader import LinkNeighborLoader\n","from sklearn.metrics import f1_score\n","import json\n","from torch_geometric.nn import to_hetero, summary\n","from torch_geometric.utils import degree\n","import wandb\n","import sys\n","import time\n","# import argparse\n","import random"]},{"cell_type":"markdown","metadata":{"id":"pSAZqcJNPVuw"},"source":["## Formatting Data"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"HBb5ZpnBGNwx","executionInfo":{"status":"ok","timestamp":1754371311595,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["inPath = data_path + '/small/HI-Small_Trans.csv'\n","outPath = data_path + \"/small/formatted_transactions.csv\"\n","if not os.path.exists(outPath) :\n","  raw = pd.read_csv(inPath)\n","  raw['From Bank'] = raw['From Bank'].astype(str)\n","  raw['To Bank'] = raw['To Bank'].astype(str)\n","  formatted = pd.DataFrame(columns = ['EdgeID', 'from_id', 'to_id', 'Timestamp', 'Amount Sent', 'Sent Currency', 'Amount Received', 'Received Currency', 'Payment Format', 'Is Laundering'])\n","\n","  formatted['EdgeID'] = raw.index\n","\n","  formatted['from_id'] = raw['From Bank'] + raw['Account']\n","  formatted['to_id'] = raw['To Bank'] + raw['Account.1']\n","  unique_accounts = pd.concat([formatted['from_id'], formatted['to_id']]).unique()\n","  account_label_encoder = LabelEncoder()\n","  account_label_encoder.fit(unique_accounts)\n","  formatted['from_id'] = account_label_encoder.transform(formatted['from_id'])\n","  formatted['to_id'] = account_label_encoder.transform(formatted['to_id'])\n","\n","  raw['Timestamp'] = pd.to_datetime(raw['Timestamp'])\n","  min_time = raw['Timestamp'].min()\n","  raw['Timestamp'] = (raw['Timestamp'] - min_time)\n","  formatted['Timestamp'] = raw['Timestamp'].dt.total_seconds()\n","\n","\n","  formatted['Amount Sent'] = raw['Amount Paid']\n","\n","  formatted['Sent Currency'] = raw['Payment Currency']\n","\n","  formatted['Amount Received'] = raw['Amount Received']\n","\n","  formatted['Received Currency'] = raw['Receiving Currency']\n","\n","  formatted['Payment Format'] = raw['Payment Format']\n","\n","  formatted['Is Laundering'] = raw['Is Laundering']\n","\n","  categorical_columns = ['Sent Currency', 'Received Currency', 'Payment Format']\n","  label_encoders = {}\n","  label_encoders['account'] = account_label_encoder\n","  for column in categorical_columns:\n","      label_encoders[column] = LabelEncoder()\n","      formatted[column] = label_encoders[column].fit_transform(formatted[column])\n","      label_encoders[column] = LabelEncoder()\n","\n","  formatted.to_csv(outPath, index=False)\n","\n","# df = pd.read_csv(inPath)\n","# f_df = pd.read_csv(outPath)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"KH80sKWBNnXi","executionInfo":{"status":"ok","timestamp":1754371311672,"user_tz":-330,"elapsed":69,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# df.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Lxm-VL1aNpaL","executionInfo":{"status":"ok","timestamp":1754371311674,"user_tz":-330,"elapsed":1,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# f_df = pd.read_csv(outPath)\n","# f_df.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"RuOBiqdZsasv","executionInfo":{"status":"ok","timestamp":1754371311686,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# f_df.iloc[1]"]},{"cell_type":"markdown","metadata":{"id":"gDqoEM-2Pb-Y"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"ZokY-w0KZ6ts"},"source":["## Data Utility Funcs"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"mw7WFxMYZVNl","executionInfo":{"status":"ok","timestamp":1754371311690,"user_tz":-330,"elapsed":2,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def to_adj_nodes_with_times(data):\n","    num_nodes = data.num_nodes\n","    timestamps = torch.zeros((data.edge_index.shape[1], 1)) if data.timestamps is None else data.timestamps.reshape((-1,1))\n","    edges = torch.cat((data.edge_index.T, timestamps), dim=1) if not isinstance(data, HeteroData) else torch.cat((data['node', 'to', 'node'].edge_index.T, timestamps), dim=1)\n","    adj_list_out = dict([(i, []) for i in range(num_nodes)])\n","    adj_list_in = dict([(i, []) for i in range(num_nodes)])\n","    for u,v,t in edges:\n","        u,v,t = int(u), int(v), int(t)\n","        adj_list_out[u] += [(v, t)]\n","        adj_list_in[v] += [(u, t)]\n","    return adj_list_in, adj_list_out\n","\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Wp1XvBc0Zhem","executionInfo":{"status":"ok","timestamp":1754371311963,"user_tz":-330,"elapsed":272,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def to_adj_edges_with_times(data):\n","    num_nodes = data.num_nodes\n","    timestamps = torch.zeros((data.edge_index.shape[1], 1)) if data.timestamps is None else data.timestamps.reshape((-1,1))\n","    edges = torch.cat((data.edge_index.T, timestamps), dim=1)\n","    # calculate adjacent edges with times per node\n","    adj_edges_out = dict([(i, []) for i in range(num_nodes)])\n","    adj_edges_in = dict([(i, []) for i in range(num_nodes)])\n","    for i, (u,v,t) in enumerate(edges):\n","        u,v,t = int(u), int(v), int(t)\n","        adj_edges_out[u] += [(i, v, t)]\n","        adj_edges_in[v] += [(i, u, t)]\n","    return adj_edges_in, adj_edges_out\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"XjQnPpQRZfsA","executionInfo":{"status":"ok","timestamp":1754371311965,"user_tz":-330,"elapsed":83,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def ports(edge_index, adj_list):\n","    ports = torch.zeros(edge_index.shape[1], 1)\n","    ports_dict = {}\n","    for v, nbs in adj_list.items():\n","        if len(nbs) < 1: continue\n","        a = np.array(nbs)\n","        a = a[a[:, -1].argsort()]\n","        _, idx = np.unique(a[:,[0]],return_index=True,axis=0)\n","        nbs_unique = a[np.sort(idx)][:,0]\n","        for i, u in enumerate(nbs_unique):\n","            ports_dict[(u,v)] = i\n","    for i, e in enumerate(edge_index.T):\n","        ports[i] = ports_dict[tuple(e.numpy())]\n","    return ports\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"A0zage6wZdIY","executionInfo":{"status":"ok","timestamp":1754371311966,"user_tz":-330,"elapsed":81,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def time_deltas(data, adj_edges_list):\n","    time_deltas = torch.zeros(data.edge_index.shape[1], 1)\n","    if data.timestamps is None:\n","        return time_deltas\n","    for v, edges in adj_edges_list.items():\n","        if len(edges) < 1: continue\n","        a = np.array(edges)\n","        a = a[a[:, -1].argsort()]\n","        a_tds = [0] + [a[i+1,-1] - a[i,-1] for i in range(a.shape[0]-1)]\n","        tds = np.hstack((a[:,0].reshape(-1,1), np.array(a_tds).reshape(-1,1)))\n","        for i,td in tds:\n","            time_deltas[i] = td\n","    return time_deltas\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"gBVmQq1rZKoW","executionInfo":{"status":"ok","timestamp":1754371311967,"user_tz":-330,"elapsed":5,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def z_norm(data):\n","    std = data.std(0).unsqueeze(0)\n","    std = torch.where(std == 0, torch.tensor(1, dtype=torch.float32).cpu(), std)\n","    return (data - data.mean(0).unsqueeze(0)) / std"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"pSx-w5XUZJuS","executionInfo":{"status":"ok","timestamp":1754371311970,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def create_hetero_obj(x,  y,  edge_index,  edge_attr, timestamps, ports):\n","    '''Creates a heterogenous graph object for reverse message passing'''\n","    data = HeteroGraphData()\n","\n","    data['node'].x = x\n","    data['node', 'to', 'node'].edge_index = edge_index\n","    data['node', 'rev_to', 'node'].edge_index = edge_index.flipud()\n","    data['node', 'to', 'node'].edge_attr = edge_attr\n","    data['node', 'rev_to', 'node'].edge_attr = edge_attr\n","    if ports:\n","        #swap the in- and outgoing port numberings for the reverse edges\n","        data['node', 'rev_to', 'node'].edge_attr[:, [-1, -2]] = data['node', 'rev_to', 'node'].edge_attr[:, [-2, -1]]\n","    data['node', 'to', 'node'].y = y\n","    data['node', 'to', 'node'].timestamps = timestamps\n","\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"6k0V6wmUaKX9"},"source":["## GrapgData Class\n","for homogeneous graphs"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"vIxgJMNIXkdL","executionInfo":{"status":"ok","timestamp":1754371312008,"user_tz":-330,"elapsed":37,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["class GraphData(Data):\n","    '''This is the homogenous graph object we use for GNN training if reverse MP is not enabled'''\n","    def __init__(\n","        self, x: OptTensor = None, edge_index: OptTensor = None, edge_attr: OptTensor = None, y: OptTensor = None, pos: OptTensor = None,\n","        readout: str = 'edge',\n","        num_nodes: int = None,\n","        timestamps: OptTensor = None,\n","        node_timestamps: OptTensor = None,\n","        **kwargs\n","        ):\n","        super().__init__(x, edge_index, edge_attr, y, pos, **kwargs)\n","        self.readout = readout\n","        self.loss_fn = 'ce'\n","        self.num_nodes = int(self.x.shape[0])\n","        self.node_timestamps = node_timestamps\n","        if timestamps is not None:\n","            self.timestamps = timestamps\n","        elif edge_attr is not None:\n","            self.timestamps = edge_attr[:,0].clone()\n","        else:\n","            self.timestamps = None\n","\n","    def add_ports(self):\n","        '''Adds port numberings to the edge features'''\n","        reverse_ports = True\n","        adj_list_in, adj_list_out = to_adj_nodes_with_times(self)\n","        in_ports = ports(self.edge_index, adj_list_in)\n","        out_ports = [ports(self.edge_index.flipud(), adj_list_out)] if reverse_ports else []\n","        self.edge_attr = torch.cat([self.edge_attr, in_ports] + out_ports, dim=1)\n","        return self\n","\n","    def add_time_deltas(self):\n","        '''Adds time deltas (i.e. the time between subsequent transactions) to the edge features'''\n","        reverse_tds = True\n","        adj_list_in, adj_list_out = to_adj_edges_with_times(self)\n","        in_tds = time_deltas(self, adj_list_in)\n","        out_tds = [time_deltas(self, adj_list_out)] if reverse_tds else []\n","        self.edge_attr = torch.cat([self.edge_attr, in_tds] + out_tds, dim=1)\n","        return self\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Q6DwpR_OZsMA"},"source":["## HeteroGraphData Class\n","for heterogeneous graphs when reverse message pasing is enabled."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"2p62CxOEZNh9","executionInfo":{"status":"ok","timestamp":1754371312014,"user_tz":-330,"elapsed":5,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["class HeteroGraphData(HeteroData):\n","    '''This is the heterogenous graph object we use for GNN training if reverse MP is enabled'''\n","    def __init__(\n","        self,\n","        readout: str = 'edge',\n","        **kwargs\n","        ):\n","        super().__init__(**kwargs)\n","        self.readout = readout\n","\n","    @property\n","    def num_nodes(self):\n","        return self['node'].x.shape[0]\n","\n","    @property\n","    def timestamps(self):\n","        return self['node', 'to', 'node'].timestamps\n","\n","    def add_ports(self):\n","        '''Adds port numberings to the edge features'''\n","        adj_list_in, adj_list_out = to_adj_nodes_with_times(self)\n","        in_ports = ports(self['node', 'to', 'node'].edge_index, adj_list_in)\n","        out_ports = ports(self['node', 'rev_to', 'node'].edge_index, adj_list_out)\n","        self['node', 'to', 'node'].edge_attr = torch.cat([self['node', 'to', 'node'].edge_attr, in_ports], dim=1)\n","        self['node', 'rev_to', 'node'].edge_attr = torch.cat([self['node', 'rev_to', 'node'].edge_attr, out_ports], dim=1)\n","        return self\n","\n","    def add_time_deltas(self):\n","        '''Adds time deltas (i.e. the time between subsequent transactions) to the edge features'''\n","        adj_list_in, adj_list_out = to_adj_edges_with_times(self)\n","        in_tds = time_deltas(self, adj_list_in)\n","        out_tds = time_deltas(self, adj_list_out)\n","        self['node', 'to', 'node'].edge_attr = torch.cat([self['node', 'to', 'node'].edge_attr, in_tds], dim=1)\n","        self['node', 'rev_to', 'node'].edge_attr = torch.cat([self['node', 'rev_to', 'node'].edge_attr, out_tds], dim=1)\n","        return self\n"]},{"cell_type":"markdown","metadata":{"id":"EDCOyQqtaCDW"},"source":["## Data handler"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"7KYNaFp9EPjg","executionInfo":{"status":"ok","timestamp":1754371312154,"user_tz":-330,"elapsed":124,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# import pandas as pd\n","# import numpy as np\n","# import torch\n","# import itertools\n","# from data_util import GraphData, HeteroData, z_norm, create_hetero_obj\n","\n","def get_data(model : 'str',\n","             formatted_data_path,\n","             ports = False,\n","             tds = False,\n","             reverse_mp = False,\n","             ):\n","    '''Loads the AML transaction data.\n","\n","    1. The data is loaded from the csv and the necessary features are chosen.\n","    2. The data is split into training, validation and test data.\n","    3. PyG Data objects are created with the respective data splits.\n","    '''\n","\n","    transaction_file = formatted_data_path\n","    df_edges = pd.read_csv(transaction_file)\n","\n","    print(f'Available Edge Features: {df_edges.columns.tolist()}')\n","\n","    df_edges['Timestamp'] = df_edges['Timestamp'] - df_edges['Timestamp'].min()\n","\n","    max_n_id = df_edges.loc[:, ['from_id', 'to_id']].to_numpy().max() + 1 # no. of unique accounts\n","    df_nodes = pd.DataFrame({'NodeID': np.arange(max_n_id), 'Feature': np.ones(max_n_id)}) # node feature dataframe for each account\n","    timestamps = torch.Tensor(df_edges['Timestamp'].to_numpy())\n","    y = torch.LongTensor(df_edges['Is Laundering'].to_numpy())\n","\n","    print(f\"Illicit ratio = {sum(y)} / {len(y)} = {sum(y) / len(y) * 100:.2f}%\")\n","    print(f\"Number of nodes (holdings doing transcations) = {df_nodes.shape[0]}\")\n","    print(f\"Number of transactions = {df_edges.shape[0]}\")\n","\n","    edge_features = ['Timestamp', 'Amount Received', 'Received Currency', 'Payment Format']\n","    node_features = ['Feature']\n","\n","    print(f'Edge features being used: {edge_features}')\n","    print(f'Node features being used: {node_features} (\"Feature\" is a placeholder feature of all 1s)')\n","\n","    x = torch.tensor(df_nodes.loc[:, node_features].to_numpy()).float()\n","    edge_index = torch.LongTensor(df_edges.loc[:, ['from_id', 'to_id']].to_numpy().T)\n","    edge_attr = torch.tensor(df_edges.loc[:, edge_features].to_numpy()).float()\n","\n","    n_days = int(timestamps.max() / (3600 * 24) + 1)\n","    n_samples = y.shape[0]\n","    print(f'number of days and transactions in the data: {n_days} days, {n_samples} transactions')\n","\n","    #data splitting\n","    daily_irs, weighted_daily_irs, daily_inds, daily_trans = [], [], [], [] #irs = illicit ratios, inds = indices, trans = transactions\n","    for day in range(n_days):\n","        l = day * 24 * 3600\n","        r = (day + 1) * 24 * 3600\n","        day_inds = torch.where((timestamps >= l) & (timestamps < r))[0]\n","        daily_irs.append(y[day_inds].float().mean())\n","        weighted_daily_irs.append(y[day_inds].float().mean() * day_inds.shape[0] / n_samples)\n","        daily_inds.append(day_inds)\n","        daily_trans.append(day_inds.shape[0])\n","\n","    split_per = [0.6, 0.2, 0.2]\n","    daily_totals = np.array(daily_trans)\n","    d_ts = daily_totals\n","    I = list(range(len(d_ts)))\n","    split_scores = dict()\n","    for i,j in itertools.combinations(I, 2):\n","        if j >= i:\n","            split_totals = [d_ts[:i].sum(), d_ts[i:j].sum(), d_ts[j:].sum()]\n","            split_totals_sum = np.sum(split_totals)\n","            split_props = [v/split_totals_sum for v in split_totals]\n","            split_error = [abs(v-t)/t for v,t in zip(split_props, split_per)]\n","            score = max(split_error) #- (split_totals_sum/total) + 1\n","            split_scores[(i,j)] = score\n","        else:\n","            continue\n","\n","    i,j = min(split_scores, key=split_scores.get)\n","    #split contains a list for each split (train, validation and test) and each list contains the days that are part of the respective split\n","    split = [list(range(i)), list(range(i, j)), list(range(j, len(daily_totals)))]\n","    print(f'Calculate split: {split}')\n","\n","    #Now, we seperate the transactions based on their indices in the timestamp array\n","    split_inds = {k: [] for k in range(3)}\n","    for i in range(3):\n","        for day in split[i]:\n","            split_inds[i].append(daily_inds[day]) #split_inds contains a list for each split (tr,val,te) which contains the indices of each day seperately\n","\n","    tr_inds = torch.cat(split_inds[0])\n","    val_inds = torch.cat(split_inds[1])\n","    te_inds = torch.cat(split_inds[2])\n","\n","    print(f\"Total train samples: {tr_inds.shape[0] / y.shape[0] * 100 :.2f}% || IR: \"\n","            f\"{y[tr_inds].float().mean() * 100 :.2f}% || Train days: {split[0][:5]}\")\n","    print(f\"Total val samples: {val_inds.shape[0] / y.shape[0] * 100 :.2f}% || IR: \"\n","        f\"{y[val_inds].float().mean() * 100:.2f}% || Val days: {split[1][:5]}\")\n","    print(f\"Total test samples: {te_inds.shape[0] / y.shape[0] * 100 :.2f}% || IR: \"\n","        f\"{y[te_inds].float().mean() * 100:.2f}% || Test days: {split[2][:5]}\")\n","\n","    #Creating the final data objects\n","    tr_x, val_x, te_x = x, x, x\n","    e_tr = tr_inds.numpy()\n","    e_val = np.concatenate([tr_inds, val_inds])\n","\n","    tr_edge_index,  tr_edge_attr,  tr_y,  tr_edge_times  = edge_index[:,e_tr],  edge_attr[e_tr],  y[e_tr],  timestamps[e_tr]\n","    val_edge_index, val_edge_attr, val_y, val_edge_times = edge_index[:,e_val], edge_attr[e_val], y[e_val], timestamps[e_val]\n","    te_edge_index,  te_edge_attr,  te_y,  te_edge_times  = edge_index,          edge_attr,        y,        timestamps\n","\n","    tr_data = GraphData (x=tr_x,  y=tr_y,  edge_index=tr_edge_index,  edge_attr=tr_edge_attr,  timestamps=tr_edge_times )\n","    val_data = GraphData(x=val_x, y=val_y, edge_index=val_edge_index, edge_attr=val_edge_attr, timestamps=val_edge_times)\n","    te_data = GraphData (x=te_x,  y=te_y,  edge_index=te_edge_index,  edge_attr=te_edge_attr,  timestamps=te_edge_times )\n","\n","    #Adding ports and time-deltas if applicable\n","    if ports:\n","        print(f\"Start: adding ports\")\n","        tr_data.add_ports()\n","        val_data.add_ports()\n","        te_data.add_ports()\n","        print(f\"Done: adding ports\")\n","    if tds:\n","        print(f\"Start: adding time-deltas\")\n","        tr_data.add_time_deltas()\n","        val_data.add_time_deltas()\n","        te_data.add_time_deltas()\n","        print(f\"Done: adding time-deltas\")\n","\n","    #Normalize data\n","    tr_data.x = val_data.x = te_data.x = z_norm(tr_data.x)\n","    if not model == 'rgcn':\n","        tr_data.edge_attr, val_data.edge_attr, te_data.edge_attr = z_norm(tr_data.edge_attr), z_norm(val_data.edge_attr), z_norm(te_data.edge_attr)\n","    else:\n","        tr_data.edge_attr[:, :-1], val_data.edge_attr[:, :-1], te_data.edge_attr[:, :-1] = z_norm(tr_data.edge_attr[:, :-1]), z_norm(val_data.edge_attr[:, :-1]), z_norm(te_data.edge_attr[:, :-1])\n","\n","    #Create heterogenous if reverese MP is enabled\n","    #TODO: if I observe wierd behaviour, maybe add .detach.clone() to all torch tensors, but I don't think they're attached to any computation graph just yet\n","    if reverse_mp:\n","        tr_data = create_hetero_obj(tr_data.x,  tr_data.y,  tr_data.edge_index,  tr_data.edge_attr, tr_data.timestamps, ports)\n","        val_data = create_hetero_obj(val_data.x,  val_data.y,  val_data.edge_index,  val_data.edge_attr, val_data.timestamps, ports)\n","        te_data = create_hetero_obj(te_data.x,  te_data.y,  te_data.edge_index,  te_data.edge_attr, te_data.timestamps, ports)\n","\n","    print(f'train data object: {tr_data}')\n","    print(f'validation data object: {val_data}')\n","    print(f'test data object: {te_data}')\n","\n","    return tr_data, val_data, te_data, tr_inds, val_inds, te_inds\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"rNrQqJ53bFvK","executionInfo":{"status":"ok","timestamp":1754371312155,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# get_data(\n","#     model = 'gat',\n","#     formatted_data_path = outPath,\n","#     ports = True,\n","#     tds = True,\n","#     reverse_mp = False\n","# )"]},{"cell_type":"markdown","metadata":{"id":"hobKvNFmO-bW"},"source":["### Test run for data processing\n","\n","Available Edge Features: ['EdgeID', 'from_id', 'to_id', 'Timestamp', 'Amount Sent', 'Sent Currency', 'Amount Received', 'Received Currency', 'Payment Format', 'Is Laundering'] \\\n","Illicit ratio = 5177 / 5078345 = 0.10% \\\n","Number of nodes (holdings doing transcations) = 515088 \\\n","Number of transactions = 5078345 \\\n","Edge features being used: ['Timestamp', 'Amount Received', 'Received Currency', 'Payment Format'] \\\n","Node features being used: ['Feature'] (\"Feature\" is a placeholder feature of all 1s) \\\n","number of days and transactions in the data: 18 days, 5078345 transactions \\\n","Calculate split: [[0, 1, 2, 3, 4, 5], [6, 7], [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]] \\\n","Total train samples: 63.98% || IR: 0.08% || Train days: [0, 1, 2, 3, 4] \\\n","Total val samples: 19.01% || IR: 0.11% || Val days: [6, 7] \\\n","Total test samples: 17.01% || IR: 0.19% || Test days: [8, 9, 10, 11, 12] \\\n","Start: adding ports \\\n","Done: adding ports \\\n","Start: adding time-deltas \\\n","Done: adding time-deltas \\\n","train data object: GraphData(x=[515088, 1], edge_index=[2, 3248921], edge_attr=[3248921, 8], y=[3248921], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[3248921]) \\\n","validation data object: GraphData(x=[515088, 1], edge_index=[2, 4214445], edge_attr=[4214445, 8], y=[4214445], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[4214445]) \\\n","test data object: GraphData(x=[515088, 1], edge_index=[2, 5078345], edge_attr=[5078345, 8], y=[5078345], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[5078345]) \\\n","(GraphData(x=[515088, 1], edge_index=[2, 3248921], edge_attr=[3248921, 8], y=[3248921], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[3248921]), \\\n"," GraphData(x=[515088, 1], edge_index=[2, 4214445], edge_attr=[4214445, 8], y=[4214445], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[4214445]), \\\n"," GraphData(x=[515088, 1], edge_index=[2, 5078345], edge_attr=[5078345, 8], y=[5078345], readout='edge', loss_fn='ce', num_nodes=515088, timestamps=[5078345]), \\\n"," tensor([      0,       1,       2,  ..., 3249981, 3249982, 3249983]), \\\n"," tensor([ 695463,  695464,  695465,  ..., 4215347, 4215348, 4215349]), \\\n"," tensor([ 812708,  812709,  812710,  ..., 5033972, 5033973, 5033974])) \\"]},{"cell_type":"markdown","metadata":{"id":"bl8d4BLfLilq"},"source":["# Architectures"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Ahxnd1W2MQXw","executionInfo":{"status":"ok","timestamp":1754371312155,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# import torch.nn as nn\n","# from torch_geometric.nn import GINEConv, BatchNorm, Linear, GATConv, PNAConv, RGCNConv\n","# import torch.nn.functional as F\n","# import torch\n","# import logging"]},{"cell_type":"markdown","metadata":{"id":"exi86CzLMWOe"},"source":["## GIN"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"RIdib3fBLmEY","executionInfo":{"status":"ok","timestamp":1754371312170,"user_tz":-330,"elapsed":18,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["class GINe(torch.nn.Module):\n","    def __init__(self, num_features, num_gnn_layers, n_classes=2,\n","                n_hidden=100, edge_updates=False, residual=True,\n","                edge_dim=None, dropout=0.0, final_dropout=0.5):\n","        super().__init__()\n","        self.n_hidden = n_hidden\n","        self.num_gnn_layers = num_gnn_layers\n","        self.edge_updates = edge_updates\n","        self.final_dropout = final_dropout\n","\n","        self.node_emb = nn.Linear(num_features, n_hidden)\n","        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n","\n","        self.convs = nn.ModuleList()\n","        self.emlps = nn.ModuleList()\n","        self.batch_norms = nn.ModuleList()\n","        for _ in range(self.num_gnn_layers):\n","            conv = GINEConv(nn.Sequential(\n","                nn.Linear(self.n_hidden, self.n_hidden),\n","                nn.ReLU(),\n","                nn.Linear(self.n_hidden, self.n_hidden)\n","                ), edge_dim=self.n_hidden)\n","            if self.edge_updates: self.emlps.append(nn.Sequential(\n","                nn.Linear(3 * self.n_hidden, self.n_hidden),\n","                nn.ReLU(),\n","                nn.Linear(self.n_hidden, self.n_hidden),\n","            ))\n","            self.convs.append(conv)\n","            self.batch_norms.append(BatchNorm(n_hidden))\n","\n","        self.mlp = nn.Sequential(Linear(n_hidden*3, 50), nn.ReLU(), nn.Dropout(self.final_dropout),Linear(50, 25), nn.ReLU(), nn.Dropout(self.final_dropout),\n","                              Linear(25, n_classes))\n","\n","    def forward(self, x, edge_index, edge_attr):\n","        src, dst = edge_index\n","\n","        x = self.node_emb(x)\n","        edge_attr = self.edge_emb(edge_attr)\n","\n","        for i in range(self.num_gnn_layers):\n","            x = (x + F.relu(self.batch_norms[i](self.convs[i](x, edge_index, edge_attr)))) / 2\n","            if self.edge_updates:\n","                edge_attr = edge_attr + self.emlps[i](torch.cat([x[src], x[dst], edge_attr], dim=-1)) / 2\n","\n","        x = x[edge_index.T].reshape(-1, 2 * self.n_hidden).relu()\n","        x = torch.cat((x, edge_attr.view(-1, edge_attr.shape[1])), 1)\n","        out = x\n","\n","        return self.mlp(out)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2sYy9FV_ML0f"},"source":["## GAT"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"JlzpFEkjMN5c","executionInfo":{"status":"ok","timestamp":1754371312214,"user_tz":-330,"elapsed":43,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["class GATe(torch.nn.Module):\n","    def __init__(self, num_features, num_gnn_layers, n_classes=2, n_hidden=100, n_heads=4, edge_updates=False, edge_dim=None, dropout=0.0, final_dropout=0.5):\n","        super().__init__()\n","        # GAT specific code\n","        tmp_out = n_hidden // n_heads\n","        n_hidden = tmp_out * n_heads\n","\n","        self.n_hidden = n_hidden\n","        self.n_heads = n_heads\n","        self.num_gnn_layers = num_gnn_layers\n","        self.edge_updates = edge_updates\n","        self.dropout = dropout\n","        self.final_dropout = final_dropout\n","\n","        self.node_emb = nn.Linear(num_features, n_hidden)\n","        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n","\n","        self.convs = nn.ModuleList()\n","        self.emlps = nn.ModuleList()\n","        self.batch_norms = nn.ModuleList()\n","\n","        for _ in range(self.num_gnn_layers):\n","            conv = GATConv(self.n_hidden, tmp_out, self.n_heads, concat = True, dropout = self.dropout, add_self_loops = True, edge_dim=self.n_hidden)\n","            if self.edge_updates: self.emlps.append(nn.Sequential(nn.Linear(3 * self.n_hidden, self.n_hidden),nn.ReLU(),nn.Linear(self.n_hidden, self.n_hidden),))\n","            self.convs.append(conv)\n","            self.batch_norms.append(BatchNorm(n_hidden))\n","\n","        self.mlp = nn.Sequential(Linear(n_hidden*3, 50), nn.ReLU(), nn.Dropout(self.final_dropout),Linear(50, 25), nn.ReLU(), nn.Dropout(self.final_dropout),Linear(25, n_classes))\n","\n","    def forward(self, x, edge_index, edge_attr):\n","        src, dst = edge_index\n","\n","        x = self.node_emb(x)\n","        edge_attr = self.edge_emb(edge_attr)\n","\n","        for i in range(self.num_gnn_layers):\n","            x = (x + F.relu(self.batch_norms[i](self.convs[i](x, edge_index, edge_attr)))) / 2\n","            if self.edge_updates:\n","                edge_attr = edge_attr + self.emlps[i](torch.cat([x[src], x[dst], edge_attr], dim=-1)) / 2\n","\n","        # logging.debug(f\"x.shape = {x.shape}, x[edge_index.T].shape = {x[edge_index.T].shape}\")\n","        x = x[edge_index.T].reshape(-1, 2 * self.n_hidden).relu()\n","        # logging.debug(f\"x.shape = {x.shape}\")\n","        x = torch.cat((x, edge_attr.view(-1, edge_attr.shape[1])), 1)\n","        # logging.debug(f\"x.shape = {x.shape}\")\n","        out = x\n","\n","        return self.mlp(out)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mgZeaqGqMDMa"},"source":["## PNA"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"HhvcMSliMFBQ","executionInfo":{"status":"ok","timestamp":1754371312238,"user_tz":-330,"elapsed":22,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["class PNA(torch.nn.Module):\n","    def __init__(self, num_features, num_gnn_layers, n_classes=2,\n","                n_hidden=100, edge_updates=True,\n","                edge_dim=None, dropout=0.0, final_dropout=0.5, deg=None):\n","        super().__init__()\n","        n_hidden = int((n_hidden // 5) * 5)\n","        self.n_hidden = n_hidden\n","        self.num_gnn_layers = num_gnn_layers\n","        self.edge_updates = edge_updates\n","        self.final_dropout = final_dropout\n","\n","        aggregators = ['mean', 'min', 'max', 'std']\n","        scalers = ['identity', 'amplification', 'attenuation']\n","\n","        self.node_emb = nn.Linear(num_features, n_hidden)\n","        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n","\n","        self.convs = nn.ModuleList()\n","        self.emlps = nn.ModuleList()\n","        self.batch_norms = nn.ModuleList()\n","        for _ in range(self.num_gnn_layers):\n","            conv = PNAConv(in_channels=n_hidden, out_channels=n_hidden,\n","                           aggregators=aggregators, scalers=scalers, deg=deg,\n","                           edge_dim=n_hidden, towers=5, pre_layers=1, post_layers=1,\n","                           divide_input=False)\n","            if self.edge_updates: self.emlps.append(nn.Sequential(\n","                nn.Linear(3 * self.n_hidden, self.n_hidden),\n","                nn.ReLU(),\n","                nn.Linear(self.n_hidden, self.n_hidden),\n","            ))\n","            self.convs.append(conv)\n","            self.batch_norms.append(BatchNorm(n_hidden))\n","\n","        self.mlp = nn.Sequential(Linear(n_hidden*3, 50), nn.ReLU(), nn.Dropout(self.final_dropout),Linear(50, 25), nn.ReLU(), nn.Dropout(self.final_dropout),\n","                              Linear(25, n_classes))\n","\n","    def forward(self, x, edge_index, edge_attr):\n","        src, dst = edge_index\n","\n","        x = self.node_emb(x)\n","        edge_attr = self.edge_emb(edge_attr)\n","\n","        for i in range(self.num_gnn_layers):\n","            x = (x + F.relu(self.batch_norms[i](self.convs[i](x, edge_index, edge_attr)))) / 2\n","            if self.edge_updates:\n","                edge_attr = edge_attr + self.emlps[i](torch.cat([x[src], x[dst], edge_attr], dim=-1)) / 2\n","\n","        logging.debug(f\"x.shape = {x.shape}, x[edge_index.T].shape = {x[edge_index.T].shape}\")\n","        x = x[edge_index.T].reshape(-1, 2 * self.n_hidden).relu()\n","        logging.debug(f\"x.shape = {x.shape}\")\n","        x = torch.cat((x, edge_attr.view(-1, edge_attr.shape[1])), 1)\n","        logging.debug(f\"x.shape = {x.shape}\")\n","        out = x\n","        return self.mlp(out)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DLbHZGpfL7eA"},"source":["## RGCN"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"cFCOfC3OL9DG","executionInfo":{"status":"ok","timestamp":1754371312262,"user_tz":-330,"elapsed":23,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["class RGCN(nn.Module):\n","    def __init__(self, num_features, edge_dim, num_relations, num_gnn_layers, n_classes=2,\n","                n_hidden=100, edge_update=False,\n","                residual=True,\n","                dropout=0.0, final_dropout=0.5, n_bases=-1):\n","        super(RGCN, self).__init__()\n","\n","        self.num_features = num_features\n","        self.num_gnn_layers = num_gnn_layers\n","        self.n_hidden = n_hidden\n","        self.residual = residual\n","        self.dropout = dropout\n","        self.final_dropout = final_dropout\n","        self.n_classes = n_classes\n","        self.edge_update = edge_update\n","        self.num_relations = num_relations\n","        self.n_bases = n_bases\n","\n","        self.node_emb = nn.Linear(num_features, n_hidden)\n","        self.edge_emb = nn.Linear(edge_dim, n_hidden)\n","\n","        self.convs = nn.ModuleList()\n","        self.bns = nn.ModuleList()\n","        self.mlp = nn.ModuleList()\n","\n","        if self.edge_update:\n","            self.emlps = nn.ModuleList()\n","            self.emlps.append(nn.Sequential(\n","                nn.Linear(3 * self.n_hidden, self.n_hidden),\n","                nn.ReLU(),\n","                nn.Linear(self.n_hidden, self.n_hidden),\n","            ))\n","\n","        for _ in range(self.num_gnn_layers):\n","            conv = RGCNConv(self.n_hidden, self.n_hidden, num_relations, num_bases=self.n_bases)\n","            self.convs.append(conv)\n","            self.bns.append(nn.BatchNorm1d(self.n_hidden))\n","\n","            if self.edge_update:\n","                self.emlps.append(nn.Sequential(\n","                    nn.Linear(3 * self.n_hidden, self.n_hidden),\n","                    nn.ReLU(),\n","                    nn.Linear(self.n_hidden, self.n_hidden),\n","                ))\n","\n","        self.mlp = nn.Sequential(Linear(n_hidden*3, 50), nn.ReLU(), nn.Dropout(self.final_dropout), Linear(50, 25), nn.ReLU(), nn.Dropout(self.final_dropout),\n","                              Linear(25, n_classes))\n","\n","    def reset_parameters(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                m.reset_parameters()\n","            elif isinstance(m, RGCNConv):\n","                m.reset_parameters()\n","            elif isinstance(m, nn.BatchNorm1d):\n","                m.reset_parameters()\n","\n","    def forward(self, x, edge_index, edge_attr):\n","        edge_type = edge_attr[:, -1].long()\n","        #edge_attr = edge_attr[:, :-1]\n","        src, dst = edge_index\n","\n","        x = self.node_emb(x)\n","        edge_attr = self.edge_emb(edge_attr)\n","\n","        for i in range(self.num_gnn_layers):\n","            x =  (x + F.relu(self.bns[i](self.convs[i](x, edge_index, edge_type)))) / 2\n","            if self.edge_update:\n","                edge_attr = (edge_attr + F.relu(self.emlps[i](torch.cat([x[src], x[dst], edge_attr], dim=-1)))) / 2\n","\n","        x = x[edge_index.T].reshape(-1, 2 * self.n_hidden).relu()\n","        x = torch.cat((x, edge_attr.view(-1, edge_attr.shape[1])), 1)\n","        x = self.mlp(x)\n","        out = x\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"YDwfJ681QcAh"},"source":["# Training Functions"]},{"cell_type":"markdown","metadata":{"id":"slDBKoufTPFW"},"source":["## Model Settings"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"2kvZtvUJTRzE","executionInfo":{"status":"ok","timestamp":1754371312291,"user_tz":-330,"elapsed":28,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["model_settings = {\n","      \"gin\": {\n","        \"params\": {\n","          \"lr\": 0.006213266113989207, \"n_hidden\": 66.00315515631006, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\",\n","          \"w_ce1\": 1.0000182882773443, \"w_ce2\": 6.275014431494497, \"norm_method\": \"z_normalize\", \"dropout\": 0.00983468338330501,\n","          \"final_dropout\": 0.10527690625126304\n","        },\n","        \"bayes_opt_params\": {\n","          \"lr\": [0.002, 0.007], \"n_hidden\": [66.0, 66.01], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [2.0, 2.001],\n","          \"loss\": [0.0, 0.1], \"w_ce1\": [1, 1.001], \"w_ce2\": [6, 12], \"norm_method\": [0, 0.001], \"dropout\": [0, 0.05],\n","          \"final_dropout\": [0, 0.2]\n","        },\n","        \"header\": \"run,tb,lr,n_hidden,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n","      },\n","\n","      \"pna\": {\n","        \"params\": {\n","          \"lr\": 0.0006116418195373612, \"n_hidden\": 20, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\", \"w_ce1\": 1.0003967674742307,\n","          \"w_ce2\": 7.077633468006714, \"norm_method\": \"z_normalize\", \"dropout\": 0.08340440094051481, \"final_dropout\": 0.28812979737686323\n","        },\n","        \"bayes_opt_params\": {\n","          \"lr\": [0.0001, 0.001], \"n_hidden\": [16, 64], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [2.00, 2.01], \"loss\": [0.0, 0.1],\n","          \"w_ce1\": [1, 1.001], \"w_ce2\": [6, 12], \"norm_method\": [0, 0.1], \"dropout\": [0.0, 0.2], \"final_dropout\": [0.0, 0.4]\n","        },\n","        \"header\": \"run,tb,lr,n_hidden,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n","      },\n","\n","      \"gat\": {\n","        \"params\": {\n","          \"lr\": 0.006, \"n_hidden\": 64, \"n_heads\": 4, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\", \"w_ce1\": 1, \"w_ce2\": 6,\n","          \"norm_method\": \"z_normalize\", \"dropout\": 0.009, \"final_dropout\": 0.1\n","        },\n","        \"bayes_opt_params\": {\n","          \"lr\": [0.01, 0.04], \"n_hidden\": [4, 24], \"n_heads\": [1.5, 4.5], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [3, 7],\n","          \"loss\": [0, 0.1], \"w_ce1\": [1, 1.001], \"w_ce2\": [1, 10], \"norm_method\": [0, 0.1], \"dropout\": [0, 0.5],\n","          \"final_dropout\": [0, 0.8]\n","        },\n","        \"header\": \"run,tb,lr,n_hidden,n_heads,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n","      },\n","\n","      \"mlp\": {\n","        \"params\": {\n","          \"lr\": 0.006213266113989207, \"n_hidden\": 66.00315515631006, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\", \"w_ce1\": 1.0000182882773443,\n","          \"w_ce2\": 9.23, \"norm_method\": \"z_normalize\", \"dropout\": 0.00983468338330501, \"final_dropout\": 0.10527690625126304\n","        },\n","        \"bayes_opt_params\": {\n","          \"lr\": [0.006, 0.0064], \"n_hidden\": [66.0, 66.01], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [2.0, 2.001], \"loss\": [0.0, 0.1],\n","          \"w_ce1\": [1, 1.001], \"w_ce2\": [6, 12], \"norm_method\": [0, 0.001], \"dropout\": [0, 0.05], \"final_dropout\": [0, 0.2]\n","        },\n","        \"header\": \"run,tb,lr,n_hidden,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n","      },\n","      \"rgcn\": {\n","        \"params\": {\n","          \"lr\": 0.006213266113989207, \"n_hidden\": 66.00315515631006, \"n_mlp_layers\": 1, \"n_gnn_layers\": 2, \"loss\": \"ce\", \"w_ce1\": 1.0000182882773443,\n","          \"w_ce2\": 9.23, \"norm_method\": \"z_normalize\", \"dropout\": 0.00983468338330501, \"final_dropout\": 0.10527690625126304\n","        },\n","        \"bayes_opt_params\": {\n","          \"lr\": [0.006, 0.0064], \"n_hidden\": [66.0, 66.01], \"n_mlp_layers\": [1, 1.001], \"n_gnn_layers\": [2.0, 2.001], \"loss\": [0.0, 0.1],\n","          \"w_ce1\": [1, 1.001], \"w_ce2\": [6, 12], \"norm_method\": [0, 0.001], \"dropout\": [0, 0.05], \"final_dropout\": [0, 0.2]\n","        },\n","        \"header\": \"run,tb,lr,n_hidden,n_mlp_layers,n_gnn_layers,loss,w_ce1,w_ce2,norm_method,dropout,final_dropout,epoch,tr_acc,tr_prec,tr_rec,tr_f1,tr_auc,val_acc,val_prec,val_rec,val_f1,val_auc,te_acc,te_prec,te_rec,te_f1,te_auc\\n\"\n","      }\n","    }"]},{"cell_type":"markdown","metadata":{"id":"SeKVD18fRFxJ"},"source":["## Training utils"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"0jHLGQcRRuxP","executionInfo":{"status":"ok","timestamp":1754371312301,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# import torch\n","# import tqdm\n","# from torch_geometric.transforms import BaseTransform\n","# from typing import Union\n","# from torch_geometric.data import Data, HeteroData\n","# from torch_geometric.loader import LinkNeighborLoader\n","# from sklearn.metrics import f1_score\n","# import json"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"nR1mpKGHRO1v","executionInfo":{"status":"ok","timestamp":1754371312322,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["class AddEgoIds(BaseTransform):\n","    r\"\"\"Add IDs to the centre nodes of the batch.\n","    \"\"\"\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, data: Union[Data, HeteroData]):\n","        x = data.x if not isinstance(data, HeteroData) else data['node'].x\n","        device = x.device\n","        ids = torch.zeros((x.shape[0], 1), device=device)\n","        if not isinstance(data, HeteroData):\n","            nodes = torch.unique(data.edge_label_index.view(-1)).to(device)\n","        else:\n","            nodes = torch.unique(data['node', 'to', 'node'].edge_label_index.view(-1)).to(device)\n","        ids[nodes] = 1\n","        if not isinstance(data, HeteroData):\n","            data.x = torch.cat([x, ids], dim=1)\n","        else:\n","            data['node'].x = torch.cat([x, ids], dim=1)\n","\n","        return data\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"7hPk3JtQRQUo","executionInfo":{"status":"ok","timestamp":1754371312334,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def extract_param(parameter_name: str, model : str) -> float:\n","    \"\"\"\n","    Extract the value of the specified parameter for the given model.\n","\n","    Args:\n","    - parameter_name (str): Name of the parameter (e.g., \"lr\").\n","    - args (argparser): Arguments given to this specific run.\n","\n","    Returns:\n","    - float: Value of the specified parameter.\n","    \"\"\"\n","    # file_path = './model_settings.json'\n","    # with open(file_path, \"r\") as file:\n","    #     data = json.load(file)\n","    # return data.get(args.model, {}).get(\"params\", {}).get(parameter_name, None)\n","    return model_settings[model][\"params\"][parameter_name]\n"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"DUsjZjJ5RUGk","executionInfo":{"status":"ok","timestamp":1754371312348,"user_tz":-330,"elapsed":13,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["\n","def add_arange_ids(data_list):\n","    '''\n","    Add the index as an id to the edge features to find seed edges in training, validation and testing.\n","\n","    Args:\n","    - data_list (str): List of tr_data, val_data and te_data.\n","    '''\n","    for data in data_list:\n","        if isinstance(data, HeteroData):\n","            data['node', 'to', 'node'].edge_attr = torch.cat([torch.arange(data['node', 'to', 'node'].edge_attr.shape[0]).view(-1, 1), data['node', 'to', 'node'].edge_attr], dim=1)\n","            offset = data['node', 'to', 'node'].edge_attr.shape[0]\n","            data['node', 'rev_to', 'node'].edge_attr = torch.cat([torch.arange(offset, data['node', 'rev_to', 'node'].edge_attr.shape[0] + offset).view(-1, 1), data['node', 'rev_to', 'node'].edge_attr], dim=1)\n","        else:\n","            data.edge_attr = torch.cat([torch.arange(data.edge_attr.shape[0]).view(-1, 1), data.edge_attr], dim=1)\n"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"JNnlsnR4RdF2","executionInfo":{"status":"ok","timestamp":1754371312372,"user_tz":-330,"elapsed":23,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["\n","\n","def get_loaders(tr_data, val_data, te_data,\n","                tr_inds, val_inds, te_inds,\n","                transform,\n","                num_neighs,\n","                batch_size,\n","                ):\n","    if isinstance(tr_data, HeteroData):\n","        tr_edge_label_index = tr_data['node', 'to', 'node'].edge_index\n","        tr_edge_label = tr_data['node', 'to', 'node'].y\n","\n","\n","        tr_loader =  LinkNeighborLoader(tr_data, num_neighbors=num_neighs,\n","                                    edge_label_index=(('node', 'to', 'node'), tr_edge_label_index),\n","                                    edge_label=tr_edge_label, batch_size=batch_size, shuffle=True, transform=transform)\n","\n","        val_edge_label_index = val_data['node', 'to', 'node'].edge_index#[:,val_inds]\n","        val_edge_label = val_data['node', 'to', 'node'].y#[val_inds]\n","\n","\n","        val_loader =  LinkNeighborLoader(val_data, num_neighbors=num_neighs,\n","                                    edge_label_index=(('node', 'to', 'node'), val_edge_label_index),\n","                                    edge_label=val_edge_label, batch_size=batch_size, shuffle=False, transform=transform)\n","\n","        te_edge_label_index = te_data['node', 'to', 'node'].edge_index#[:,te_inds]\n","        te_edge_label = te_data['node', 'to', 'node'].y#[te_inds]\n","\n","\n","        te_loader =  LinkNeighborLoader(te_data, num_neighbors=num_neighs,\n","                                    edge_label_index=(('node', 'to', 'node'), te_edge_label_index),\n","                                    edge_label=te_edge_label, batch_size=batch_size, shuffle=False, transform=transform)\n","    else:\n","        tr_loader =  LinkNeighborLoader(tr_data, num_neighbors=num_neighs, batch_size=batch_size, shuffle=True, transform=transform)\n","        val_loader = LinkNeighborLoader(val_data,num_neighbors=num_neighs, edge_label_index=val_data.edge_index,\n","                                        edge_label=val_data.y, batch_size=batch_size, shuffle=False, transform=transform) # y[val_inds] , edge_index[:, val_inds],\n","        te_loader =  LinkNeighborLoader(te_data,num_neighbors=num_neighs, edge_label_index=te_data.edge_index,\n","                                edge_label=te_data.y, batch_size=batch_size, shuffle=False, transform=transform)# y[te_inds] , edge_index[:, te_inds],\n","\n","    return tr_loader, val_loader, te_loader\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"LEk1ZcQZReV7","executionInfo":{"status":"ok","timestamp":1754371312395,"user_tz":-330,"elapsed":22,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["@torch.no_grad()\n","def evaluate_homo(loader, inds, model, data, device, tqdm, args_data):\n","    '''Evaluates the model performane for homogenous graph data.'''\n","    preds = []\n","    ground_truths = []\n","    for batch in tqdm.tqdm(loader, disable=not tqdm):\n","        #select the seed edges from which the batch was created\n","        # inds = inds.detach().cpu() # This is not needed\n","        # batch_edge_inds = inds[batch.input_id.detach().cpu()] # This is incorrect\n","        # batch_edge_ids = loader.data.edge_attr.detach().cpu()[batch_edge_inds, 0] # This is incorrect\n","        batch_edge_ids = loader.data.edge_attr.detach().cpu()[batch.input_id.detach().cpu(), 0] # Corrected indexing\n","        mask = torch.isin(batch.edge_attr[:, 0].detach().cpu(), batch_edge_ids)\n","\n","        #add the seed edges that have not been sampled to the batch\n","        missing = ~torch.isin(batch_edge_ids, batch.edge_attr[:, 0].detach().cpu())\n","\n","        if missing.sum() != 0 and (args_data == 'Small_J' or args_data == 'Small_Q'):\n","            missing_ids = batch_edge_ids[missing].int()\n","            n_ids = batch.n_id\n","            add_edge_index = data.edge_index[:, missing_ids].detach().clone()\n","            node_mapping = {value.item(): idx for idx, value in enumerate(n_ids)}\n","            add_edge_index = torch.tensor([[node_mapping[val.item()] for val in row] for row in add_edge_index])\n","            add_edge_attr = data.edge_attr[missing_ids, :].detach().clone()\n","            add_y = data.y[missing_ids].detach().clone()\n","\n","            batch.edge_index = torch.cat((batch.edge_index, add_edge_index), 1)\n","            batch.edge_attr = torch.cat((batch.edge_attr, add_edge_attr), 0)\n","            batch.y = torch.cat((batch.y, add_y), 0)\n","\n","            mask = torch.cat((mask, torch.ones(add_y.shape[0], dtype=torch.bool)))\n","\n","        #remove the unique edge id from the edge features, as it's no longer needed\n","        batch.edge_attr = batch.edge_attr[:, 1:]\n","\n","        with torch.no_grad():\n","            batch.to(device)\n","            out = model(batch.x, batch.edge_index, batch.edge_attr)\n","            out = out[mask]\n","            pred = out.argmax(dim=-1)\n","            preds.append(pred)\n","            ground_truths.append(batch.y[mask])\n","    pred = torch.cat(preds, dim=0).cpu().numpy()\n","    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n","    f1 = f1_score(ground_truth, pred)\n","\n","    return f1"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"7bMUgEj2Rk4x","executionInfo":{"status":"ok","timestamp":1754371312417,"user_tz":-330,"elapsed":20,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["@torch.no_grad()\n","def evaluate_hetero(loader, inds, model, data, device, tqdm, args_data):\n","    '''Evaluates the model performane for heterogenous graph data.'''\n","    preds = []\n","    ground_truths = []\n","    for batch in tqdm.tqdm(loader, disable=not tqdm):\n","        #select the seed edges from which the batch was created\n","        # inds = inds.detach().cpu() # This is not needed\n","        batch_edge_inds = batch['node', 'to', 'node'].input_id.detach().cpu() # Use input_id directly\n","        batch_edge_ids = loader.data['node', 'to', 'node'].edge_attr.detach().cpu()[batch_edge_inds, 0]\n","        mask = torch.isin(batch['node', 'to', 'node'].edge_attr[:, 0].detach().cpu(), batch_edge_ids)\n","\n","        #add the seed edges that have not been sampled to the batch\n","        missing = ~torch.isin(batch_edge_ids, batch['node', 'to', 'node'].edge_attr[:, 0].detach().cpu())\n","\n","        if missing.sum() != 0 and (args_data == 'Small_J' or args_data == 'Small_Q'):\n","            missing_ids = batch_edge_ids[missing].int()\n","            n_ids = batch['node'].n_id\n","            add_edge_index = data['node', 'to', 'node'].edge_index[:, missing_ids].detach().clone()\n","            node_mapping = {value.item(): idx for idx, value in enumerate(n_ids)}\n","            add_edge_index = torch.tensor([[node_mapping[val.item()] for val in row] for row in add_edge_index])\n","            add_edge_attr = data['node', 'to', 'node'].edge_attr[missing_ids, :].detach().clone()\n","            add_y = data['node', 'to', 'node'].y[missing_ids].detach().clone()\n","\n","            batch['node', 'to', 'node'].edge_index = torch.cat((batch['node', 'to', 'node'].edge_index, add_edge_index), 1)\n","            batch['node', 'to', 'node'].edge_attr = torch.cat((batch['node', 'to', 'node'].edge_attr, add_edge_attr), 0)\n","            batch['node', 'to', 'node'].y = torch.cat((batch['node', 'to', 'node'].y, add_y), 0)\n","\n","            mask = torch.cat((mask, torch.ones(add_y.shape[0], dtype=torch.bool)))\n","\n","        #remove the unique edge id from the edge features, as it's no longer needed\n","        batch['node', 'to', 'node'].edge_attr = batch['node', 'to', 'node'].edge_attr[:, 1:]\n","        batch['node', 'rev_to', 'node'].edge_attr = batch['node', 'rev_to', 'node'].edge_attr[:, 1:]\n","\n","        with torch.no_grad():\n","            batch.to(device)\n","            out = model(batch.x_dict, batch.edge_index_dict, batch.edge_attr_dict)\n","            out = out[('node', 'to', 'node')]\n","            out = out[mask]\n","            pred = out.argmax(dim=-1)\n","            preds.append(pred)\n","            ground_truths.append(batch['node', 'to', 'node'].y[mask])\n","    pred = torch.cat(preds, dim=0).cpu().numpy()\n","    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n","    f1 = f1_score(ground_truth, pred)\n","\n","    return f1"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"84JjuSlaQesS","executionInfo":{"status":"ok","timestamp":1754371312430,"user_tz":-330,"elapsed":12,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def save_model(model, optimizer, epoch, unique_name, finetune, model_save_path):\n","    # Save the model in a dictionary\n","    torch.save({\n","                'epoch': epoch + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict()\n","                }, f'{model_save_path}/checkpoint_{unique_name}{\"\" if not finetune else \"_finetuned\"}.tar')\n","\n","def load_model(model, device, unique_name, config, model_load_path):\n","    checkpoint = torch.load(f'{model_load_path}/checkpoint_{unique_name}.tar')\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","    return model, optimizer"]},{"cell_type":"markdown","metadata":{"id":"LOmFtj37aDrZ"},"source":["## Training Handler"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"661G1WFQaSod","executionInfo":{"status":"ok","timestamp":1754371312447,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# import torch\n","# import tqdm\n","# from sklearn.metrics import f1_score\n","# # from train_util import AddEgoIds, extract_param, add_arange_ids, get_loaders, evaluate_homo, evaluate_hetero, save_model, load_model\n","# # from models import GINe, PNA, GATe, RGCN\n","# from torch_geometric.data import Data, HeteroData\n","# from torch_geometric.nn import to_hetero, summary\n","# from torch_geometric.utils import degree\n","# import wandb\n","# # import logging"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"2a6f8-Cuippl","executionInfo":{"status":"ok","timestamp":1754371312479,"user_tz":-330,"elapsed":31,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def get_model(sample_batch,\n","              config,\n","              model : str,\n","              emlps,\n","              ):\n","    n_feats = sample_batch.x.shape[1] if not isinstance(sample_batch, HeteroData) else sample_batch['node'].x.shape[1]\n","    e_dim = (sample_batch.edge_attr.shape[1] - 1) if not isinstance(sample_batch, HeteroData) else (sample_batch['node', 'to', 'node'].edge_attr.shape[1] - 1)\n","\n","    if model == \"gin\":\n","        model = GINe(\n","                num_features=n_feats, num_gnn_layers=config.n_gnn_layers, n_classes=2,\n","                n_hidden=round(config.n_hidden), residual=False, edge_updates=emlps, edge_dim=e_dim,\n","                dropout=config.dropout, final_dropout=config.final_dropout\n","                )\n","    elif model == \"gat\":\n","        model = GATe(\n","                num_features=n_feats, num_gnn_layers=config.n_gnn_layers, n_classes=2,\n","                n_hidden=round(config.n_hidden), n_heads=round(config.n_heads),\n","                edge_updates=emlps, edge_dim=e_dim,\n","                dropout=config.dropout, final_dropout=config.final_dropout\n","                )\n","    elif model == \"pna\":\n","        if not isinstance(sample_batch, HeteroData):\n","            d = degree(sample_batch.edge_index[1], dtype=torch.long)\n","        else:\n","            index = torch.cat((sample_batch['node', 'to', 'node'].edge_index[1], sample_batch['node', 'rev_to', 'node'].edge_index[1]), 0)\n","            d = degree(index, dtype=torch.long)\n","        deg = torch.bincount(d, minlength=1)\n","        model = PNA(\n","            num_features=n_feats, num_gnn_layers=config.n_gnn_layers, n_classes=2,\n","            n_hidden=round(config.n_hidden), edge_updates=emlps, edge_dim=e_dim,\n","            dropout=config.dropout, deg=deg, final_dropout=config.final_dropout\n","            )\n","    elif config.model == \"rgcn\":\n","        model = RGCN(\n","            num_features=n_feats, edge_dim=e_dim, num_relations=8, num_gnn_layers=round(config.n_gnn_layers),\n","            n_classes=2, n_hidden=round(config.n_hidden),\n","            edge_update=emlps, dropout=config.dropout, final_dropout=config.final_dropout, n_bases=None #(maybe)\n","        )\n","\n","    return model\n"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"4L5r5EiuiIml","executionInfo":{"status":"ok","timestamp":1754371312562,"user_tz":-330,"elapsed":82,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def train_homo(tr_loader, val_loader, te_loader,\n","               tr_inds, val_inds, te_inds,\n","               model, optimizer,\n","               loss_fn,\n","               args_tqdm ,\n","               args_data : str,\n","               unique_name : str,\n","               finetune ,\n","               model_save,\n","               config, device,\n","               val_data, te_data,\n","               model_save_path):\n","    #training\n","    best_val_f1 = 0\n","    for epoch in range(config.epochs):\n","        total_loss = total_examples = 0\n","        preds = []\n","        ground_truths = []\n","        for batch in tqdm.tqdm(tr_loader, disable=not args_tqdm):\n","            optimizer.zero_grad()\n","            #select the seed edges from which the batch was created\n","            batch_edge_ids = tr_loader.data.edge_attr.detach().cpu()[batch.input_id.detach().cpu(), 0]\n","\n","            mask = torch.isin(batch.edge_attr[:, 0].detach().cpu(), batch_edge_ids)\n","\n","            #remove the unique edge id from the edge features, as it's no longer needed\n","            batch.edge_attr = batch.edge_attr[:, 1:]\n","\n","            batch.to(device)\n","            out = model(batch.x, batch.edge_index, batch.edge_attr)\n","            pred = out[mask]\n","            ground_truth = batch.y[mask]\n","            preds.append(pred.argmax(dim=-1))\n","            ground_truths.append(ground_truth)\n","            loss = loss_fn(pred, ground_truth)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += float(loss) * pred.numel()\n","            total_examples += pred.numel()\n","\n","        pred = torch.cat(preds, dim=0).detach().cpu().numpy()\n","        ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n","        f1 = f1_score(ground_truth, pred)\n","        wandb.log({\"f1/train\": f1}, step=epoch)\n","        print(f'Train F1: {f1:.4f}') # logging.info\n","\n","        #evaluate\n","        val_f1 = evaluate_homo(val_loader, val_inds, model, val_data, device, tqdm, args_data)\n","        te_f1 = evaluate_homo(te_loader, te_inds, model, te_data, device, tqdm, args_data)\n","\n","        wandb.log({\"f1/validation\": val_f1}, step=epoch)\n","        wandb.log({\"f1/test\": te_f1}, step=epoch)\n","        print(f'Validation F1: {val_f1:.4f}')# logging.info\n","        print(f'Test F1: {te_f1:.4f}')# logging.info\n","\n","        if epoch == 0:\n","            wandb.log({\"best_test_f1\": te_f1}, step=epoch)\n","        elif val_f1 > best_val_f1:\n","            best_val_f1 = val_f1\n","            wandb.log({\"best_test_f1\": te_f1}, step=epoch)\n","            if model_save:\n","                save_model(model, optimizer, epoch, unique_name, finetune, model_save_path)\n","\n","    return model"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"0B0D42PPaF4o","executionInfo":{"status":"ok","timestamp":1754371312571,"user_tz":-330,"elapsed":74,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def train_hetero(tr_loader, val_loader, te_loader,\n","                 tr_inds, val_inds, te_inds,\n","                 model, optimizer,\n","                 loss_fn,\n","                 args_tqdm,\n","                 args_data,\n","                 unique_name,\n","                 finetune,\n","                 model_save,\n","                 config, device,\n","                 val_data, te_data,\n","                 model_save_path):\n","    #training\n","    best_val_f1 = 0\n","    for epoch in range(config.epochs):\n","        total_loss = total_examples = 0\n","        preds = []\n","        ground_truths = []\n","        for batch in tqdm.tqdm(tr_loader, disable=not args_tqdm):\n","            optimizer.zero_grad()\n","            #select the seed edges from which the batch was created\n","            # inds = tr_inds.detach().cpu() # This is not needed\n","            # batch_edge_inds = batch['node', 'to', 'node'].input_id.detach().cpu() # Use input_id directly\n","            batch_edge_ids = tr_loader.data['node', 'to', 'node'].edge_attr.detach().cpu()[batch['node', 'to', 'node'].input_id.detach().cpu(), 0] # Corrected indexing\n","            mask = torch.isin(batch['node', 'to', 'node'].edge_attr[:, 0].detach().cpu(), batch_edge_ids)\n","\n","            #remove the unique edge id from the edge features, as it's no longer needed\n","            batch['node', 'to', 'node'].edge_attr = batch['node', 'to', 'node'].edge_attr[:, 1:]\n","            batch['node', 'rev_to', 'node'].edge_attr = batch['node', 'rev_to', 'node'].edge_attr[:, 1:]\n","\n","            batch.to(device)\n","            out = model(batch.x_dict, batch.edge_index_dict, batch.edge_attr_dict)\n","            out = out[('node', 'to', 'node')]\n","            pred = out[mask]\n","            ground_truth = batch['node', 'to', 'node'].y[mask]\n","            preds.append(pred.argmax(dim=-1))\n","            ground_truths.append(batch['node', 'to', 'node'].y[mask])\n","            loss = loss_fn(pred, ground_truth)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += float(loss) * pred.numel()\n","            total_examples += pred.numel()\n","\n","        pred = torch.cat(preds, dim=0).detach().cpu().numpy()\n","        ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n","        f1 = f1_score(ground_truth, pred)\n","        wandb.log({\"f1/train\": f1}, step=epoch)\n","        print(f'Train F1: {f1:.4f}') # logging.info\n","\n","        #evaluate\n","        val_f1 = evaluate_hetero(val_loader, val_inds, model, val_data, device, tqdm, args_data)\n","        te_f1 = evaluate_hetero(te_loader, te_inds, model, te_data, device, tqdm, args_data)\n","\n","        wandb.log({\"f1/validation\": val_f1}, step=epoch)\n","        wandb.log({\"f1/test\": te_f1}, step=epoch)\n","        print(f'Validation F1: {val_f1:.4f}')# logging.info\n","        print(f'Test F1: {te_f1:.4f}')# logging.info\n","\n","        if epoch == 0:\n","            wandb.log({\"best_test_f1\": te_f1}, step=epoch)\n","        elif val_f1 > best_val_f1:\n","            best_val_f1 = val_f1\n","            wandb.log({\"best_test_f1\": te_f1}, step=epoch)\n","            if model_save:\n","                save_model(model, optimizer, epoch, unique_name, finetune, model_save_path)\n","\n","    return model"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"vjksa0TSix4r","executionInfo":{"status":"ok","timestamp":1754371312580,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def train_gnn(tr_data, val_data, te_data,\n","              tr_inds, val_inds, te_inds,\n","              tqdm,\n","              testing,\n","              n_epochs,\n","              batch_size,\n","              model_name : str,\n","              unique_name,\n","              args_data,\n","              num_neighs,\n","              ego,\n","              reverse_mp,\n","              finetune,\n","              emlps,\n","              model_save,\n","              model_load_path,\n","              model_save_path,\n","              ):\n","    #set device\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    #define a model config dictionary and wandb logging at the same time\n","    wandb.init(\n","        mode=\"disabled\" if testing else \"online\",\n","        project=\"Multi_GAT_3\", #replace this with your wandb project name if you want to use wandb logging\n","\n","        config={\n","            \"epochs\": n_epochs,\n","            \"batch_size\": batch_size,\n","            \"model\": model_name,\n","            \"data\": args_data,\n","            \"num_neighbors\": num_neighs,\n","            \"lr\": extract_param(\"lr\", model_name),\n","            \"n_hidden\": extract_param(\"n_hidden\", model_name),\n","            \"n_gnn_layers\": extract_param(\"n_gnn_layers\", model_name),\n","            \"loss\": \"ce\",\n","            \"w_ce1\": extract_param(\"w_ce1\", model_name),\n","            \"w_ce2\": extract_param(\"w_ce2\", model_name),\n","            \"dropout\": extract_param(\"dropout\", model_name),\n","            \"final_dropout\": extract_param(\"final_dropout\", model_name),\n","            \"n_heads\": extract_param(\"n_heads\", model_name) if model_name == 'gat' else None\n","        }\n","    )\n","\n","    config = wandb.config\n","\n","    #set the transform if ego ids should be used\n","    if ego:\n","        transform = AddEgoIds()\n","    else:\n","        transform = None\n","\n","    #add the unique ids to later find the seed edges\n","    add_arange_ids([tr_data, val_data, te_data])\n","\n","    tr_loader, val_loader, te_loader = get_loaders(tr_data, val_data, te_data, tr_inds, val_inds, te_inds, transform, num_neighs, batch_size)\n","\n","    #get the model\n","    sample_batch = next(iter(tr_loader))\n","    model = get_model(sample_batch, config, model_name, emlps)\n","\n","    if reverse_mp:\n","        model = to_hetero(model, te_data.metadata(), aggr='mean')\n","\n","    if finetune:\n","        model, optimizer = load_model(model, device, unique_name, config, model_load_path)\n","    else:\n","        model.to(device)\n","        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n","\n","    sample_batch.to(device)\n","    sample_x = sample_batch.x if not isinstance(sample_batch, HeteroData) else sample_batch.x_dict\n","    sample_edge_index = sample_batch.edge_index if not isinstance(sample_batch, HeteroData) else sample_batch.edge_index_dict\n","    if isinstance(sample_batch, HeteroData):\n","        sample_batch['node', 'to', 'node'].edge_attr = sample_batch['node', 'to', 'node'].edge_attr[:, 1:]\n","        sample_batch['node', 'rev_to', 'node'].edge_attr = sample_batch['node', 'rev_to', 'node'].edge_attr[:, 1:]\n","    else:\n","        sample_batch.edge_attr = sample_batch.edge_attr[:, 1:]\n","    sample_edge_attr = sample_batch.edge_attr if not isinstance(sample_batch, HeteroData) else sample_batch.edge_attr_dict\n","    print(summary(model, sample_x, sample_edge_index, sample_edge_attr)) # logging.info\n","\n","    loss_fn = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor([config.w_ce1, config.w_ce2]).to(device))\n","\n","    if reverse_mp:\n","        model = train_hetero(tr_loader, val_loader, te_loader,\n","                             tr_inds, val_inds, te_inds,\n","                             model, optimizer,\n","                             loss_fn,\n","                             tqdm,\n","                             args_data,\n","                             unique_name,\n","                             finetune,\n","                             model_save,\n","                             config,\n","                             device,\n","                             val_data, te_data,\n","                             model_save_path)\n","    else:\n","        model = train_homo(tr_loader, val_loader, te_loader,\n","                           tr_inds, val_inds, te_inds,\n","                           model, optimizer,\n","                           loss_fn,\n","                           tqdm,\n","                           args_data,\n","                           unique_name,\n","                           finetune,\n","                           model_save,\n","                           config, device,\n","                           val_data, te_data,\n","                           model_save_path)\n","\n","    wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"SP72Kao1mV_K"},"source":["## Inference Functions"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"uHvqfXINmo26","executionInfo":{"status":"ok","timestamp":1754371312601,"user_tz":-330,"elapsed":1,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# import torch\n","# import pandas as pd\n","# # from train_util import AddEgoIds, extract_param, add_arange_ids, get_loaders, evaluate_homo, evaluate_hetero\n","# # from training import get_model\n","# from torch_geometric.nn import to_hetero, summary\n","# import wandb\n","# import logging\n","# import os\n","# import sys\n","# import time"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"cXn7XQ_rmaOA","executionInfo":{"status":"ok","timestamp":1754371312605,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# script_start = time.time()\n","\n","def infer_gnn(tr_data, val_data, te_data,\n","              tr_inds, val_inds, te_inds,\n","              testing,\n","              n_epochs,\n","              batch_size,\n","              model_name : str,\n","              unique_name,\n","              args_data,\n","              num_neighs,\n","              ego,\n","              reverse_mp,\n","              finetune,\n","              emlps,\n","              model_save,\n","              model_load_path,\n","              model_save_path,):\n","    #set device\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    #define a model config dictionary and wandb logging at the same time\n","    wandb.init(\n","        mode=\"disabled\" if testing else \"online\",\n","        project=\"Anti_money_laundering\",\n","\n","        config={\n","            \"epochs\": n_epochs,\n","            \"batch_size\": batch_size,\n","            \"model\": model_name,\n","            \"data\": args_data,\n","            \"num_neighbors\": num_neighs,\n","            \"lr\": extract_param(\"lr\", model_name),\n","            \"n_hidden\": extract_param(\"n_hidden\", model_name),\n","            \"n_gnn_layers\": extract_param(\"n_gnn_layers\", model_name),\n","            \"loss\": \"ce\",\n","            \"w_ce1\": extract_param(\"w_ce1\", model_name),\n","            \"w_ce2\": extract_param(\"w_ce2\", model_name),\n","            \"dropout\": extract_param(\"dropout\", model_name),\n","            \"final_dropout\": extract_param(\"final_dropout\", model_name),\n","            \"n_heads\": extract_param(\"n_heads\", model_name) if model_name == 'gat' else None\n","        }\n","    )\n","\n","    config = wandb.config\n","\n","    #set the transform if ego ids should be used\n","    if ego:\n","        transform = AddEgoIds()\n","    else:\n","        transform = None\n","\n","    #add the unique ids to later find the seed edges\n","    add_arange_ids([tr_data, val_data, te_data])\n","\n","    tr_loader, val_loader, te_loader = get_loaders(tr_data, val_data, te_data,\n","                                                   tr_inds, val_inds, te_inds,\n","                                                   transform,\n","                                                   num_neighs, batch_size,)\n","\n","    #get the model\n","    sample_batch = next(iter(tr_loader))\n","    model = get_model(sample_batch, config, model_name, emlps)\n","\n","    if reverse_mp:\n","        model = to_hetero(model, te_data.metadata(), aggr='mean')\n","\n","    # if not (avg_tps or finetune):\n","    #     command = \" \".join(sys.argv)\n","    #     name = \"\"\n","    #     name = '-'.join(name.split('-')[3:])\n","    #     unique_name = name\n","\n","    print(\"=> loading model checkpoint\")# logging.info\n","    checkpoint = torch.load(f'{model_load_path}/checkpoint_{unique_name}.tar')\n","    start_epoch = checkpoint['epoch']\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    model.to(device)\n","\n","    print(\"=> loaded checkpoint (epoch {})\".format(start_epoch)) # logging.info\n","\n","    if not reverse_mp:\n","        te_f1 = evaluate_homo(te_loader, te_inds,\n","                                               model,\n","                                               te_data,\n","                                               device,\n","                                               tqdm,\n","                                               args_data,\n","                                               )\n","    else:\n","        te_f1 = evaluate_hetero(te_loader, te_inds,\n","                                                 model,\n","                                                 te_data,\n","                                                 device,\n","                                                 tqdm,\n","                                                 args_data,\n","                                                 )\n","    wandb.log({\"f1/GAT2\" : te_f1} , step = start_epoch)\n","    print(f'Test F1: {te_f1:.4f}')# logging.info\n","\n","    wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"pYBCH09Mi37w"},"source":[" # Training"]},{"cell_type":"markdown","metadata":{"id":"tdwADkRrjNgZ"},"source":["## utils"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"kqmX5khCjcxc","executionInfo":{"status":"ok","timestamp":1754371312609,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# # import argparse\n","# import numpy as np\n","# import torch\n","# import random\n","# # import logging\n","# import os\n","# import sys"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"SlE7gmxkjUkp","executionInfo":{"status":"ok","timestamp":1754371312616,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# def create_parser():\n","#     parser = argparse.ArgumentParser()\n","\n","#     #Adaptations\n","#     parser.add_argument(\"--emlps\", action='store_true', help=\"Use emlps in GNN training\")\n","#     parser.add_argument(\"--reverse_mp\", action='store_true', help=\"Use reverse MP in GNN training\")\n","#     parser.add_argument(\"--ports\", action='store_true', help=\"Use port numberings in GNN training\")\n","#     parser.add_argument(\"--tds\", action='store_true', help=\"Use time deltas (i.e. the time between subsequent transactions) in GNN training\")\n","#     parser.add_argument(\"--ego\", action='store_true', help=\"Use ego IDs in GNN training\")\n","\n","#     #Model parameters\n","#     parser.add_argument(\"--batch_size\", default=8192, type=int, help=\"Select the batch size for GNN training\")\n","#     parser.add_argument(\"--n_epochs\", default=100, type=int, help=\"Select the number of epochs for GNN training\")\n","#     parser.add_argument('--num_neighs', nargs='+', default=[100,100], help='Pass the number of neighors to be sampled in each hop (descending).')\n","\n","#     #Misc\n","#     parser.add_argument(\"--seed\", default=1, type=int, help=\"Select the random seed for reproducability\")\n","#     parser.add_argument(\"--tqdm\", action='store_true', help=\"Use tqdm logging (when running interactively in terminal)\")\n","#     parser.add_argument(\"--data\", default=None, type=str, help=\"Select the AML dataset. Needs to be either small or medium.\", required=True)\n","#     parser.add_argument(\"--model\", default=None, type=str, help=\"Select the model architecture. Needs to be one of [gin, gat, rgcn, pna]\", required=True)\n","#     parser.add_argument(\"--testing\", action='store_true', help=\"Disable wandb logging while running the script in 'testing' mode.\")\n","#     parser.add_argument(\"--save_model\", action='store_true', help=\"Save the best model.\")\n","#     parser.add_argument(\"--unique_name\", action='store_true', help=\"Unique name under which the model will be stored.\")\n","#     parser.add_argument(\"--finetune\", action='store_true', help=\"Fine-tune a model. Note that args.unique_name needs to point to the pre-trained model.\")\n","#     parser.add_argument(\"--inference\", action='store_true', help=\"Load a trained model and only do AML inference with it. args.unique name needs to point to the trained model.\")\n","\n","#     return parser"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"nEcnyWUOjZV_","executionInfo":{"status":"ok","timestamp":1754371312618,"user_tz":-330,"elapsed":1,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# def logger_setup():\n","#     # Setup logging\n","#     log_directory = \"logs\"\n","#     if not os.path.exists(log_directory):\n","#         os.makedirs(log_directory)\n","#     logging.basicConfig(\n","#         level=logging.INFO,\n","#         format=\"%(asctime)s [%(levelname)-5.5s] %(message)s\",\n","#         handlers=[\n","#             logging.FileHandler(os.path.join(log_directory, \"logs.log\")),     ## log to local log file\n","#             logging.StreamHandler(sys.stdout)          ## log also to stdout (i.e., print to screen)\n","#         ]\n","#     )\n"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"Hvm24Cvqi6XY","executionInfo":{"status":"ok","timestamp":1754371312623,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["def set_seed(seed: int = 0) -> None:\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    logging.info(f\"Random seed set as {seed}\")"]},{"cell_type":"markdown","metadata":{"id":"m8eoF9XnjwoF"},"source":["## : _ :"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"SYXa_pwzj9l5","executionInfo":{"status":"ok","timestamp":1754371312625,"user_tz":-330,"elapsed":1,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# import time\n","# import logging\n","# # from util import create_parser, set_seed, logger_setup\n","# # from data_loading import get_data\n","# # from training import train_gnn\n","# # from inference import infer_gnn\n","# import json"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"6OGPIlz3loZ4","executionInfo":{"status":"ok","timestamp":1754371313032,"user_tz":-330,"elapsed":16,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# args\n","    # parser = create_parser()\n","    # args = parser.parse_args()\n","\n","args_tqdm = True\n","emlps = True\n","reverse_mp = True\n","port = True\n","tds = False\n","ego = True\n","batch_size = 8192\n","n_epochs = 11\n","num_neighs = [100, 100]\n","seed = 11\n","testing = False\n","model_save = True\n","unique_name = 'Multi_GAT_2'\n","finetune = False\n","inference = True\n","args_data = \"small\"\n","model_name = \"gat\""]},{"cell_type":"code","execution_count":51,"metadata":{"id":"JtIcTpdyly9V","executionInfo":{"status":"ok","timestamp":1754371313036,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["    # with open('data_config.json', 'r') as config_file:\n","    #     data_config = json.load(config_file)\n","\n","    #data_config variables\n","\n","aml_data = data_path\n","model_load_path = model_load_path\n","model_save_path = model_save_path\n","formatted_data_path = data_path + f\"/{args_data}/formatted_transactions.csv\""]},{"cell_type":"code","execution_count":52,"metadata":{"id":"smG1ZwjGm5Yb","executionInfo":{"status":"ok","timestamp":1754371313049,"user_tz":-330,"elapsed":12,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# Setup logging\n","# logger_setup()"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"Sx_WTeZqmcxz","executionInfo":{"status":"ok","timestamp":1754371313065,"user_tz":-330,"elapsed":23,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["#set seed\n","set_seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"3OXlyqgYYx7a"},"source":["## prepared_data\n"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"7VbUpO2EtKm-","executionInfo":{"status":"ok","timestamp":1754371313068,"user_tz":-330,"elapsed":2,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["if computation=='local' :\n","  prepared_data_path = '../data/small/prepared_data_Multi_GIN'\n","else :\n","  prepared_data_path = '/content/drive/MyDrive/uco_fraud_detector/data/AML/small/prepared_data_Multi_GIN'"]},{"cell_type":"markdown","metadata":{"id":"5cct3Dq8MzV-"},"source":["### Memoizing Prepared_data"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"klJPAlB7M3yi","executionInfo":{"status":"ok","timestamp":1754371313072,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# prepared_data = {\n","#     'tr_data': tr_data,\n","#     'val_data': val_data,\n","#     'te_data': te_data,\n","#     'tr_inds': tr_inds,\n","#     'val_inds': val_inds,\n","#     'te_inds': te_inds,\n","#     'reverse_mp': reverse_mp,\n","#     'emlps': emlps,\n","#     'port': port,\n","#     'tds': tds,\n","#     'ego': ego,\n","# }"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"LcD7b_bQNQwo","executionInfo":{"status":"ok","timestamp":1754371313073,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# import pickle\n","# pickle.dump(prepared_data, open(prepared_data_path, 'wb'))"]},{"cell_type":"markdown","metadata":{"id":"9M_p7rwMMuaS"},"source":["### Extracting prepared_data"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11810,"status":"ok","timestamp":1754371324882,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"},"user_tz":-330},"id":"i4rqSDedtsmP","outputId":"0a30dabc-f86d-4bbe-9d0e-b3d09c0dee57"},"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['tr_data', 'val_data', 'te_data', 'tr_inds', 'val_inds', 'te_inds', 'reverse_mp', 'emlps', 'tds', 'port', 'ego'])\n"]}],"source":["import pickle\n","prepared_data = pickle.load(open(prepared_data_path, 'rb'))\n","print(prepared_data.keys())"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"9aAdXKRdt9wj","executionInfo":{"status":"ok","timestamp":1754371324883,"user_tz":-330,"elapsed":8,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["tr_data = prepared_data['tr_data']\n","val_data = prepared_data['val_data']\n","te_data = prepared_data['te_data']\n","tr_inds = prepared_data['tr_inds']\n","val_inds = prepared_data['val_inds']\n","te_inds = prepared_data['te_inds']"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":27,"status":"ok","timestamp":1754371324905,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"},"user_tz":-330},"id":"3BrAQYC2ubKm","outputId":"3b5a223b-766b-40f4-d18e-ac5c2b4ffceb"},"outputs":[{"output_type":"stream","name":"stdout","text":["tr_data : \n"," HeteroGraphData(\n","  readout='edge',\n","  node={ x=[515088, 1] },\n","  (node, to, node)={\n","    edge_index=[2, 3248921],\n","    edge_attr=[3248921, 6],\n","    y=[3248921],\n","    timestamps=[3248921],\n","  },\n","  (node, rev_to, node)={\n","    edge_index=[2, 3248921],\n","    edge_attr=[3248921, 6],\n","  }\n",") \n","\n","val_data : \n"," HeteroGraphData(\n","  readout='edge',\n","  node={ x=[515088, 1] },\n","  (node, to, node)={\n","    edge_index=[2, 4214445],\n","    edge_attr=[4214445, 6],\n","    y=[4214445],\n","    timestamps=[4214445],\n","  },\n","  (node, rev_to, node)={\n","    edge_index=[2, 4214445],\n","    edge_attr=[4214445, 6],\n","  }\n",") \n","\n","te_data : \n"," HeteroGraphData(\n","  readout='edge',\n","  node={ x=[515088, 1] },\n","  (node, to, node)={\n","    edge_index=[2, 5078345],\n","    edge_attr=[5078345, 6],\n","    y=[5078345],\n","    timestamps=[5078345],\n","  },\n","  (node, rev_to, node)={\n","    edge_index=[2, 5078345],\n","    edge_attr=[5078345, 6],\n","  }\n",") \n","\n","tr_inds : \n"," tensor([      0,       1,       2,  ..., 3249981, 3249982, 3249983]) \n","\n","val_inds : \n"," tensor([ 695463,  695464,  695465,  ..., 4215347, 4215348, 4215349]) \n","\n","te_inds : \n"," tensor([ 812708,  812709,  812710,  ..., 5033972, 5033973, 5033974]) \n","\n"]}],"source":["print('tr_data : \\n',tr_data,'\\n')\n","print('val_data : \\n',val_data,'\\n')\n","print('te_data : \\n',te_data,'\\n')\n","print('tr_inds : \\n',tr_inds,'\\n')\n","print('val_inds : \\n',val_inds,'\\n')\n","print('te_inds : \\n',te_inds,'\\n')"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1754371324906,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"},"user_tz":-330},"id":"uU2bIOf4ulo5","outputId":"62c08498-442b-4003-9c3a-a981c7074b94"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":60}],"source":["torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"id":"T98WVaqfCuHp"},"source":["## .."]},{"cell_type":"code","execution_count":61,"metadata":{"id":"MlhkacQmmkWt","executionInfo":{"status":"ok","timestamp":1754371324906,"user_tz":-330,"elapsed":2,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[],"source":["# print(\"Retrieving data\") #logging.info\n","# t1 = time.perf_counter()\n","\n","# tr_data, val_data, te_data, tr_inds, val_inds, te_inds = get_data(model_name,\n","#                                                                   formatted_data_path,\n","#                                                                   port,\n","#                                                                   tds,\n","#                                                                   reverse_mp,\n","#                                                                   )\n","\n","# t2 = time.perf_counter()\n","# print(f\"Retrieved data in {t2-t1:.2f}s \\n\")#logging.info"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":691},"id":"Nw5oA8qpnRFl","outputId":"ee75054d-3e53-4534-bcfc-03c4eb23efd7","executionInfo":{"status":"ok","timestamp":1754371936657,"user_tz":-330,"elapsed":611751,"user":{"displayName":"Rony Chowdhury","userId":"15876296757527007481"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running Inference\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msayak2103\u001b[0m (\u001b[33msayak2103-iiest-shibpur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250805_052214-c90qumng</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering/runs/c90qumng' target=\"_blank\">morning-microwave-13</a></strong> to <a href='https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering' target=\"_blank\">https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering/runs/c90qumng' target=\"_blank\">https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering/runs/c90qumng</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n","  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"]},{"output_type":"stream","name":"stdout","text":["=> loading model checkpoint\n","=> loaded checkpoint (epoch 9)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 620/620 [09:52<00:00,  1.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Test F1: 0.1836\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1/GAT2</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1/GAT2</td><td>0.18364</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">morning-microwave-13</strong> at: <a href='https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering/runs/c90qumng' target=\"_blank\">https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering/runs/c90qumng</a><br> View project at: <a href='https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering' target=\"_blank\">https://wandb.ai/sayak2103-iiest-shibpur/Anti_money_laundering</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250805_052214-c90qumng/logs</code>"]},"metadata":{}}],"source":["if not inference:\n","    #Training\n","    print(f\"Running Training\") #logging.info\n","    train_gnn(tr_data, val_data, te_data,\n","              tr_inds, val_inds, te_inds,\n","              args_tqdm,\n","              testing,\n","              n_epochs,\n","              batch_size,\n","              model_name,\n","              unique_name,\n","              args_data,\n","              num_neighs,\n","              ego,\n","              reverse_mp,\n","              finetune,\n","              emlps,\n","              model_save,\n","              model_load_path,\n","              model_save_path,)\n","else:\n","    #Inference\n","    print(f\"Running Inference\")#logging.info\n","    infer_gnn(tr_data, val_data, te_data,\n","              tr_inds, val_inds, te_inds,\n","              testing,\n","              n_epochs,\n","              batch_size,\n","              model_name,\n","              unique_name,\n","              args_data,\n","              num_neighs,\n","              ego,\n","              reverse_mp,\n","              finetune,\n","              emlps,\n","              model_save,\n","              model_load_path,\n","              model_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j70jxGa8Nmoc"},"outputs":[],"source":["# wandb_key = '829bf058a06bc7d70a24dac55a8e2a3e981f59c1'"]},{"cell_type":"markdown","metadata":{"id":"5ZUwY6vtIeMs"},"source":["## Testing Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27437034"},"outputs":[],"source":["# import networkx as nx\n","# import matplotlib.pyplot as plt\n","\n","# # Assuming 'te_data' is your GraphData object containing the entire graph\n","# # You might need to adjust this based on which data split you want to visualize\n","\n","# # Create a NetworkX graph\n","# G = nx.Graph()\n","\n","# # Add nodes\n","# # The number of nodes is inferred from the maximum node index in edge_index\n","# num_nodes = te_data.edge_index.max().item() + 1\n","# G.add_nodes_from(range(num_nodes))\n","\n","# # Add edges with attributes\n","# # Assuming the edge_index is in the format [from_nodes, to_nodes]\n","# from_nodes = te_data.edge_index[0].tolist()\n","# to_nodes = te_data.edge_index[1].tolist()\n","# edge_attributes = te_data.edge_attr.tolist() # Assuming edge_attr is a tensor\n","\n","# for i in range(len(from_nodes)):\n","#     # You can add edge attributes here if needed, e.g., weight=edge_attributes[i][some_attribute_index]\n","#     G.add_edge(from_nodes[i], to_nodes[i])\n","\n","# # Define node colors based on the 'y' attribute\n","# # Assuming 'y' is an edge attribute in te_data.edge_attr and indicates the classification\n","# # You need to know which column in edge_attr corresponds to 'y'\n","# # For example, if 'Is Laundering' was the last column before adding the unique id (which is now the first),\n","# # and you removed the unique id in the evaluation function, the 'y' classification might be something else now.\n","# # Let's assume for now that the classification is in the last column of the original edge_attr before any additions or removals.\n","# # You might need to adjust the index below based on your actual data structure after preprocessing.\n","\n","# # Find the original 'Is Laundering' column index before adding the unique ID\n","# # Looking at the data loading, 'Is Laundering' is the last column of the original 'formatted' dataframe.\n","# # In get_data, edge_attr is created from ['Timestamp', 'Amount Received', 'Received Currency', 'Payment Format']\n","# # and then possibly 'ports' and 'time_deltas' are added.\n","# # 'y' is created separately from 'Is Laundering'.\n","# # So, 'y' is a separate tensor for each data split, not an edge attribute.\n","\n","# # Let's assume you want to color the nodes based on whether they are involved in any laundering transaction.\n","# # We can get the nodes involved in laundering transactions from the edge_index where the corresponding y is 1.\n","# laundering_edge_indices = torch.where(te_data.y == 1)[0]\n","# laundering_nodes = torch.unique(te_data.edge_index[:, laundering_edge_indices].view(-1)).tolist()\n","\n","# node_colors = ['red' if node in laundering_nodes else 'blue' for node in G.nodes()]\n","\n","\n","# # Draw the graph\n","# plt.figure(figsize=(12, 12))\n","# nx.draw(G, with_labels=False, node_size=10, node_color=node_colors, width=0.5)\n","# plt.title(\"Graph Visualization colored by involvement in laundering\")\n","# plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Ol-bJqjfyImJ","TITr06Uyzukv","pSAZqcJNPVuw","gDqoEM-2Pb-Y","ZokY-w0KZ6ts","6k0V6wmUaKX9","Q6DwpR_OZsMA","bl8d4BLfLilq","exi86CzLMWOe","2sYy9FV_ML0f","mgZeaqGqMDMa","DLbHZGpfL7eA","slDBKoufTPFW","SeKVD18fRFxJ","LOmFtj37aDrZ","SP72Kao1mV_K","tdwADkRrjNgZ","3OXlyqgYYx7a","5cct3Dq8MzV-","9M_p7rwMMuaS","5ZUwY6vtIeMs"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.20"}},"nbformat":4,"nbformat_minor":0}